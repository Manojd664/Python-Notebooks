{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Activation, Dense, Dropout\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import sklearn.datasets as skds\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "      <th>news</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>datasets\\train\\rec.sport.baseball\\102736</td>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>From: cubbie@garnet.berkeley.edu (            ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>datasets\\train\\comp.sys.mac.hardware\\50485</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>From: gnelson@pion.rutgers.edu (Gregory Nelson...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>datasets\\train\\sci.crypt\\15246</td>\n",
       "      <td>sci.crypt</td>\n",
       "      <td>From: crypt-comments@math.ncsu.edu\\nSubject: C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>datasets\\train\\comp.sys.mac.hardware\\51904</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>From:  ()\\nSubject: Re: Quadra SCSI Problems??...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>datasets\\train\\alt.atheism\\53144</td>\n",
       "      <td>alt.atheism</td>\n",
       "      <td>From: keith@cco.caltech.edu (Keith Allan Schne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>datasets\\train\\comp.sys.mac.hardware\\50458</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "      <td>From: taihou@chromium.iss.nus.sg (Tng Tai Hou)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>datasets\\train\\comp.windows.x\\66981</td>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>From: huub@cwi.nl (Huub Bakker)\\nSubject: wait...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>datasets\\train\\comp.windows.x\\67231</td>\n",
       "      <td>comp.windows.x</td>\n",
       "      <td>From: lanzo@tekelec.com (Mark Lanzo)\\nSubject:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>datasets\\train\\sci.med\\59250</td>\n",
       "      <td>sci.med</td>\n",
       "      <td>Subject: Why isolate it?\\nFrom: chinsz@eis.cal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>datasets\\train\\sci.electronics\\53591</td>\n",
       "      <td>sci.electronics</td>\n",
       "      <td>From: seema@madvlsi.columbia.edu (Seema Varma)...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     filename               category  \\\n",
       "0    datasets\\train\\rec.sport.baseball\\102736     rec.sport.baseball   \n",
       "1  datasets\\train\\comp.sys.mac.hardware\\50485  comp.sys.mac.hardware   \n",
       "2              datasets\\train\\sci.crypt\\15246              sci.crypt   \n",
       "3  datasets\\train\\comp.sys.mac.hardware\\51904  comp.sys.mac.hardware   \n",
       "4            datasets\\train\\alt.atheism\\53144            alt.atheism   \n",
       "5  datasets\\train\\comp.sys.mac.hardware\\50458  comp.sys.mac.hardware   \n",
       "6         datasets\\train\\comp.windows.x\\66981         comp.windows.x   \n",
       "7         datasets\\train\\comp.windows.x\\67231         comp.windows.x   \n",
       "8                datasets\\train\\sci.med\\59250                sci.med   \n",
       "9        datasets\\train\\sci.electronics\\53591        sci.electronics   \n",
       "\n",
       "                                                news  \n",
       "0  From: cubbie@garnet.berkeley.edu (            ...  \n",
       "1  From: gnelson@pion.rutgers.edu (Gregory Nelson...  \n",
       "2  From: crypt-comments@math.ncsu.edu\\nSubject: C...  \n",
       "3  From:  ()\\nSubject: Re: Quadra SCSI Problems??...  \n",
       "4  From: keith@cco.caltech.edu (Keith Allan Schne...  \n",
       "5  From: taihou@chromium.iss.nus.sg (Tng Tai Hou)...  \n",
       "6  From: huub@cwi.nl (Huub Bakker)\\nSubject: wait...  \n",
       "7  From: lanzo@tekelec.com (Mark Lanzo)\\nSubject:...  \n",
       "8  Subject: Why isolate it?\\nFrom: chinsz@eis.cal...  \n",
       "9  From: seema@madvlsi.columbia.edu (Seema Varma)...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For reproducibility\n",
    "np.random.seed(1237)\n",
    "#loading training files\n",
    "files_train = skds.load_files(\"datasets\\\\train\",load_content=False)\n",
    "label_index = files_train.target\n",
    "label_names = files_train.target_names\n",
    "labelled_files = files_train.filenames\n",
    "data_tags = [\"filename\",\"category\",\"news\"]\n",
    "data_list = []\n",
    "# Read and add data from file to a list\n",
    "i=0\n",
    "for f in labelled_files:\n",
    "    data_list.append((f,label_names[label_index[i]],Path(f).read_text()))\n",
    "    i += 1\n",
    " \n",
    "# We have training data available as dictionary filename, category, data\n",
    "data = pd.DataFrame.from_records(data_list, columns=data_tags)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets take 80% data as training and remaining 20% for test.\n",
    "train_size = int(len(data) * .8)\n",
    " \n",
    "train_posts = data['news'][:train_size]\n",
    "train_tags = data['category'][:train_size]\n",
    "train_files_names = data['filename'][:train_size]\n",
    " \n",
    "test_posts = data['news'][train_size:]\n",
    "test_tags = data['category'][train_size:]\n",
    "test_files_names = data['filename'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 20 news groups\n",
    "num_labels = 20\n",
    "vocab_size = 15000\n",
    "batch_size = 100\n",
    " \n",
    "# define Tokenizer with Vocab Size\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(train_posts)\n",
    " \n",
    "x_train = tokenizer.texts_to_matrix(train_posts, mode='tfidf')\n",
    "x_test = tokenizer.texts_to_matrix(test_posts, mode='tfidf')\n",
    " \n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoder = LabelBinarizer()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 512)               7680512   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20)                10260     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 20)                0         \n",
      "=================================================================\n",
      "Total params: 7,953,428\n",
      "Trainable params: 7,953,428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8145 samples, validate on 906 samples\n",
      "Epoch 1/30\n",
      "8145/8145 [==============================] - 33s 4ms/step - loss: 1.1731 - acc: 0.6915 - val_loss: 0.3956 - val_acc: 0.8874\n",
      "Epoch 2/30\n",
      "8145/8145 [==============================] - 28s 3ms/step - loss: 0.1518 - acc: 0.9703 - val_loss: 0.3961 - val_acc: 0.8940\n",
      "Epoch 3/30\n",
      "8145/8145 [==============================] - 28s 3ms/step - loss: 0.0596 - acc: 0.9899 - val_loss: 0.3862 - val_acc: 0.9062\n",
      "Epoch 4/30\n",
      "8145/8145 [==============================] - 28s 3ms/step - loss: 0.0384 - acc: 0.9947 - val_loss: 0.4055 - val_acc: 0.8962\n",
      "Epoch 5/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0333 - acc: 0.9959 - val_loss: 0.3936 - val_acc: 0.9040\n",
      "Epoch 6/30\n",
      "8145/8145 [==============================] - 28s 3ms/step - loss: 0.0257 - acc: 0.9972 - val_loss: 0.4708 - val_acc: 0.8951\n",
      "Epoch 7/30\n",
      "8145/8145 [==============================] - 28s 3ms/step - loss: 0.0348 - acc: 0.9951 - val_loss: 0.4441 - val_acc: 0.8985\n",
      "Epoch 8/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0402 - acc: 0.9953 - val_loss: 0.4937 - val_acc: 0.8985\n",
      "Epoch 9/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0332 - acc: 0.9950 - val_loss: 0.6121 - val_acc: 0.8775\n",
      "Epoch 10/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0436 - acc: 0.9950 - val_loss: 0.5173 - val_acc: 0.8951\n",
      "Epoch 11/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0363 - acc: 0.9959 - val_loss: 0.5512 - val_acc: 0.8852\n",
      "Epoch 12/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0335 - acc: 0.9971 - val_loss: 0.6683 - val_acc: 0.8841\n",
      "Epoch 13/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0484 - acc: 0.9953 - val_loss: 0.6814 - val_acc: 0.8841\n",
      "Epoch 14/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0387 - acc: 0.9963 - val_loss: 0.5785 - val_acc: 0.8918\n",
      "Epoch 15/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0466 - acc: 0.9959 - val_loss: 0.7027 - val_acc: 0.8775\n",
      "Epoch 16/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0647 - acc: 0.9893 - val_loss: 0.6779 - val_acc: 0.8863\n",
      "Epoch 17/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0634 - acc: 0.9909 - val_loss: 0.7400 - val_acc: 0.8675\n",
      "Epoch 18/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0461 - acc: 0.9944 - val_loss: 0.6699 - val_acc: 0.8819\n",
      "Epoch 19/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0342 - acc: 0.9958 - val_loss: 0.8538 - val_acc: 0.8698\n",
      "Epoch 20/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0475 - acc: 0.9929 - val_loss: 0.8578 - val_acc: 0.8797\n",
      "Epoch 21/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0628 - acc: 0.9920 - val_loss: 1.0344 - val_acc: 0.8598\n",
      "Epoch 22/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.1191 - acc: 0.9853 - val_loss: 0.8528 - val_acc: 0.8675\n",
      "Epoch 23/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0444 - acc: 0.9928 - val_loss: 0.7753 - val_acc: 0.8841\n",
      "Epoch 24/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0367 - acc: 0.9942 - val_loss: 0.7931 - val_acc: 0.8896\n",
      "Epoch 25/30\n",
      "8145/8145 [==============================] - 30s 4ms/step - loss: 0.0719 - acc: 0.9917 - val_loss: 0.7241 - val_acc: 0.8819\n",
      "Epoch 26/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0330 - acc: 0.9956 - val_loss: 0.7892 - val_acc: 0.8786\n",
      "Epoch 27/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0393 - acc: 0.9951 - val_loss: 0.8090 - val_acc: 0.8808\n",
      "Epoch 28/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0441 - acc: 0.9948 - val_loss: 0.8062 - val_acc: 0.8929\n",
      "Epoch 29/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0364 - acc: 0.9961 - val_loss: 0.7408 - val_acc: 0.8874\n",
      "Epoch 30/30\n",
      "8145/8145 [==============================] - 29s 4ms/step - loss: 0.0348 - acc: 0.9971 - val_loss: 0.7653 - val_acc: 0.8929\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_labels))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    " \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    " \n",
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2263/2263 [==============================] - 2s 712us/step\n",
      "Test accuracy: 0.884666374996074\n",
      "datasets\\train\\alt.atheism\\53114\n",
      "Actual label:alt.atheism\n",
      "Predicted label: alt.atheism\n",
      "datasets\\train\\comp.graphics\\38666\n",
      "Actual label:comp.graphics\n",
      "Predicted label: comp.graphics\n",
      "datasets\\train\\sci.med\\58932\n",
      "Actual label:sci.med\n",
      "Predicted label: sci.med\n",
      "datasets\\train\\sci.crypt\\15212\n",
      "Actual label:sci.crypt\n",
      "Predicted label: sci.crypt\n",
      "datasets\\train\\comp.os.ms-windows.misc\\9695\n",
      "Actual label:comp.os.ms-windows.misc\n",
      "Predicted label: comp.os.ms-windows.misc\n",
      "datasets\\train\\rec.sport.baseball\\104482\n",
      "Actual label:rec.sport.baseball\n",
      "Predicted label: rec.sport.baseball\n",
      "datasets\\train\\soc.religion.christian\\20731\n",
      "Actual label:soc.religion.christian\n",
      "Predicted label: misc.forsale\n",
      "datasets\\train\\comp.graphics\\38583\n",
      "Actual label:comp.graphics\n",
      "Predicted label: comp.graphics\n",
      "datasets\\train\\rec.sport.hockey\\52638\n",
      "Actual label:rec.sport.hockey\n",
      "Predicted label: rec.sport.hockey\n",
      "datasets\\train\\rec.sport.hockey\\52636\n",
      "Actual label:rec.sport.hockey\n",
      "Predicted label: rec.sport.baseball\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test,\n",
    "                       batch_size=batch_size, verbose=1)\n",
    "\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "text_labels = encoder.classes_\n",
    "\n",
    "for i in range(10):\n",
    "    prediction = model.predict(np.array([x_test[i]]))\n",
    "    predicted_label = text_labels[np.argmax(prediction[0])]\n",
    "    print(test_files_names.iloc[i])\n",
    "    print('Actual label:' + test_tags.iloc[i])\n",
    "    print(\"Predicted label: \" + predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# creates a HDF5 file 'my_model.h5'\n",
    "model.model.save('my_model.h5')\n",
    " \n",
    "# Save Tokenizer i.e. Vocabulary\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Model' object has no attribute 'load_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-59103833b186>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load our saved model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# load tokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Model' object has no attribute 'load_model'"
     ]
    }
   ],
   "source": [
    "# load our saved model\n",
    "model = model.model.load_model('my_model.h5')\n",
    " \n",
    "# load tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
